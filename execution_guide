Run the following command to install the necessary dependencies:
    `pip install fastapi uvicorn langchain ollama wikipedia`
or run the command in the terminal
    `pip install -r .\requirements.tsx`
If the IDE still cannot recognize the libraries and packages, install them independently or using the IDE suggestions.


Steps to run:

1. Pull the LLMs you will be using from Ollama
    (In a terminal outside of your IDE)
    - run the command `ollama` to confirm it is installed. Alternatively, you may run Ollama
      by clicking its application icon in your local environment.
    - run the command `ollama pull mistral` to download the model from the internet. It may take some time and make sure you have the space on your computer for it.
    - confirm that the model is downloaded with the command `ollama list` and view the model.

2. Run the FastAPI (which you will be querying the chatbots, and therefore, the LLms)
    (In your IDE terminal)
    - run `uvicorn api.main:app --reload` (where uvicorn is the command to run the file found at api.main:app)
    - open a browser and enter the link `http://127.0.0.1:8000/docs`

3. Now that FastAPI is running, we can use our chatbots
    - Navigate to the POST /chat endpoint
    - Click the button "Try it out"
    - Modify the request body 'message' with your prompt or query for the agent. The request body will look like this (with your query):
        {
            "message": "What is the weather in New York today?"
        }
    - Click execute and wait for the agent to generate its response
    - Once the page has finished loading, scroll down to the "Response" section of the page and view the "Server Response".
      The response generated by the agent can be view in the block "Response body" in json format,
      along with other details including the curl, request URL and response headers. An example response is below,
        {
            "response": "To provide you with the most accurate information, I would typically use a weather API to get the current weather conditions for a specific location. Since I don't have access to such an API at this moment, let me share with you that as of now, I cannot give you the exact weather in New York today. However, you can easily find out by checking a reliable weather website or app. Have a great day!"
        }

4. When your done, close everything
    - stop running the FastAPI in your IDE terminal
    - stop running Ollama
